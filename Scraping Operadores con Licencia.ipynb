{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "datasetFinal=[]\n",
    "\n",
    "page = urllib.request.urlopen(\"file:///F:\\Bluesblock, SA _ Dirección General de Ordenación del Juego.html\")\n",
    "print(page)\n",
    "\n",
    "soup = BeautifulSoup(page,\"lxml\")\n",
    "\n",
    "contenidos = soup.find(attrs={'id':'operatorContent'})\n",
    "\n",
    "# Campo NOMBRE\n",
    "nombre = contenidos.find(attrs={'id':'operatorTitle'}).text.strip() # Strip para eliminar EOF\n",
    "\n",
    "# Campo LICENCIAS(SINGULARES)\n",
    "licencias = contenidos.find(attrs={'id':'operatorSingular'}).find_all('li')\n",
    "lic=[]\n",
    "\n",
    "for licencia in licencias:\n",
    "    lic.append(licencia.text)\n",
    "    \n",
    "# Campo DOMINIOS\n",
    "dominios = contenidos.find(attrs={'id':'opetatorBody'}).find_all('li')\n",
    "dom=[]\n",
    "\n",
    "for dominio in dominios:\n",
    "    dom.append(dominio.find('a').text)\n",
    "    \n",
    "datasetFinal.append((nombre,lic,dom))\n",
    "\n",
    "print(datasetFinal)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(datasetFinal, columns=['nombre','lic','dom'])\n",
    "df.head()\n",
    "df.tail()\n",
    "df.to_csv('f:/trump_lies.csv',index=False, encoding='utf-8')\n",
    "df = pd.read_csv('trump_lies.csv',encoding='utf-8')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Con archivos locales guardados con el navegador\n",
    "\n",
    "file1 = \"file:///F:\\PEC1WEBSCRAPING\\Buscador de Operadores _ Dirección General de Ordenación del Juego.html\"\n",
    "file2 = \"file:///F:\\PEC1WEBSCRAPING\\Buscador de Operadores _ Dirección General de Ordenación del Juego2.html\"\n",
    "file3 = \"file:///F:\\PEC1WEBSCRAPING\\Buscador de Operadores _ Dirección General de Ordenación del Juego3.html\"\n",
    "\n",
    "# URL remotas\n",
    "# CONCURSOS\n",
    "url1 = \"https://www.ordenacionjuego.es/es/operadores/buscar?field_got_tid=All&field_gat_tid=All&field_gct_tid=999993&field_dominio=\"\n",
    "# APUESTAS\n",
    "url2 = \"https://www.ordenacionjuego.es/es/operadores/buscar?field_got_tid=All&field_gat_tid=999992&field_gct_tid=All&field_dominio=\"\n",
    "# OTROS JUEGOS\n",
    "url3 = \"https://www.ordenacionjuego.es/es/operadores/buscar?field_got_tid=999991&field_gat_tid=All&field_gct_tid=All&field_dominio=\"\n",
    "\n",
    "urls = (url1,url2,url3)\n",
    "#urls = {file1,file2,file3}\n",
    "\n",
    "\n",
    "# CON URL REMOTA\n",
    "\n",
    "# Dos alternativas:\n",
    "#   - CASO 1: No almacenar el tipo de licencia singular (concursos, apuestas u otros)\n",
    "#   - CASO 2: Almacenar el tipo de licencia\n",
    "# NOTA: Se ha implementado sólo el CASO 1, para el caso 2 habría que crear un campo adicional para almacenar el tipo de \n",
    "# licencia; en cada iteración un tipo diferente por lo que habría empresas repetidas con mismo nombre, url pero distintas \n",
    "# licencias. \n",
    "# Almacenar el tipo de licencia podría ser útil por ejemplo si se desea realizar un estudio más específico por categorías\n",
    "\n",
    "# CASO 1 (sólo es necesario un diccionario para las tres iteraciones, el diccionario no admite duplicados en el índice)\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "# datURL almacena los nombres y urls \n",
    "\n",
    "datURL = dict()\n",
    "\n",
    "for url in urls:\n",
    "    \n",
    "    pagina = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(pagina,\"lxml\")\n",
    "    contenidos = soup.find(\"div\",class_=\"view-content\").find_all(\"a\")\n",
    "\n",
    "    for empresa in contenidos:\n",
    "        nombre = empresa.text.strip()\n",
    "        link = empresa.get(\"href\").strip()\n",
    "        datURL[nombre]=link\n",
    "        #print(nombre,link)\n",
    "     \n",
    "# Web scraping de empresas individuales   \n",
    "# Con los resultados almacenados en el diccionario datURL, se realiza scraping sobre cada página individual de cada empresa\n",
    "\n",
    "datasetFinal = []\n",
    "\n",
    "url = \"file:///F:\\PEC1WEBSCRAPING\\Bluesblock, SA _ Dirección General de Ordenación del Juego.html\"\n",
    "\n",
    "if url != '':\n",
    "#for url in datURL.values():\n",
    "\n",
    "    pagina = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(pagina,\"lxml\")\n",
    "    contenidos = soup.find(attrs={'id':'operatorContent'})\n",
    "\n",
    "    # Campo NOMBRE\n",
    "    nombre = contenidos.find(attrs={'id':'operatorTitle'}).text.strip() # Strip para eliminar EOF\n",
    "\n",
    "    # Campo LICENCIAS(SINGULARES)\n",
    "    licencias = contenidos.find(attrs={'id':'operatorSingular'}).find_all('li')\n",
    "    lic=[]\n",
    "\n",
    "    for licencia in licencias:\n",
    "        lic.append(licencia.text)\n",
    "    \n",
    "    # Campo DOMINIOS\n",
    "    dominios = contenidos.find(attrs={'id':'opetatorBody'}).find_all('li')\n",
    "    dom=[]\n",
    "\n",
    "    for dominio in dominios:\n",
    "        dom.append(dominio.find('a').text)\n",
    "        \n",
    "    datasetFinal.append((nombre,lic,dom))\n",
    "    print(nombre,lic,dom)\n",
    "    \n",
    "# ¿CÓMO ALMACENAR DOMINIOS Y LICENCIAS SINGULARES?\n",
    "\n",
    "# ALMACENAMIENTO EN DATAFRAME\n",
    "#import pandas as pd\n",
    "#df = pd.DataFrame(records, columns=['date','lie','explanation','url'])\n",
    "#df.head()\n",
    "#df.tail()\n",
    "#df['date'] = pd.to_datetime(df['date']) # yyyy-mm-dd\n",
    "#df.to_csv('trump_lies.csv',index=False, encoding='utf-8')\n",
    "#df = pd.read_csv('trump_lies.csv',parse_dates=['date'],encoding='utf-8')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(datasetFinal, columns=['nombre','lic','dom'])\n",
    "df.head()\n",
    "df.tail()\n",
    "df.to_csv('f:/trump_lies.csv',index=False, encoding='utf-8')\n",
    "#df = pd.read_csv('trump_lies.csv',encoding='utf-8')\n",
    "\n",
    "#for valores in zip(datURL.keys(),datURL.values()):\n",
    "#    print(valores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
